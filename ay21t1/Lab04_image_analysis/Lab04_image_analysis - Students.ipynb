{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmNJuCZLiuMJ"
   },
   "source": [
    "# Lab 4 - Image Analysis\n",
    "\n",
    "In this lab, you will learn how to:\n",
    "* Detect facial attributes from images sing [Face++](https://www.faceplusplus.com/)\n",
    "* Create Pandas Dataframe From JSON instance\n",
    "* Identify the happiest landmarks in Singapore\n",
    "\n",
    "This lab is written by Jisun AN (jisunan@smu.edu.sg) and Michelle KAN (michellekan@smu.edu.sg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRHv9QzEiuMM"
   },
   "source": [
    "# Face++ (Faceplusplus)\n",
    "\n",
    "Face++ AI Open Platform offers computer vision technologies that enable you to read and understand the world better. \n",
    "\n",
    "Among many products of Face++, in this lab, we will use their Face Detection API. \n",
    "\n",
    "It detects and locates human faces within an image, and returns various attributes of faces including gender, age, smile leve, etc. See below image as an example. \n",
    "\n",
    "![Face Detection example by Face++](https://github.com/anjisun221/css_codes/blob/main/ay21t1/Lab04_image_analysis/img/facepp_demo.png?raw=true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QA8bjHFNiuMN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNATJneRiuMO"
   },
   "source": [
    "## Part 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tU8RpfsiuMO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQNzKNSqiuMP",
    "outputId": "336038ce-3601-48ab-82f9-2fb64e217d3a"
   },
   "outputs": [],
   "source": [
    "# Add Google Drive as an accessible path (Optional if you are running from Jupyter Notebook)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# change path to the designated google drive folder (e.g., %cd /content/drive/My Drive/Colab Notebooks/SMT203/Lab04)\n",
    "# otherwise, data will be saved in /content folder which you may have issue locating\n",
    "%cd /content/drive/My Drive/Colab Notebooks/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBu8LFJ-iuMP"
   },
   "source": [
    "### Let's download a few python files to call the Face++ APIs \n",
    "#### a) Below code block should download four files: `facepp.py`, `ImagePro.py`,  `structures.py`, and `compat.py`, in the same folder where your jupyter notebook is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uynQ726YiuMQ",
    "outputId": "050579be-ef87-4dac-fb33-0ede91a956da",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"./facepp21\", exist_ok=True)\n",
    "\n",
    "!wget -O 'facepp21/facepp.py' https://raw.githubusercontent.com/anjisun221/css_codes/main/ay21t1/Lab04_image_analysis/facepp21/facepp.py\n",
    "!wget -O 'facepp21/ImagePro.py' https://raw.githubusercontent.com/anjisun221/css_codes/main/ay21t1/Lab04_image_analysis/facepp21/ImagePro.py\n",
    "!wget -O 'facepp21/structures.py' https://raw.githubusercontent.com/anjisun221/css_codes/main/ay21t1/Lab04_image_analysis/facepp21/structures.py\n",
    "!wget -O 'facepp21/compat.py' https://raw.githubusercontent.com/anjisun221/css_codes/main/ay21t1/Lab04_image_analysis/facepp21/compat.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7lOw7YviuMR"
   },
   "source": [
    "#### b) Let's get datasets we will use in this lab as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3z-lWOatiuMR",
    "outputId": "d6dc73f7-5780-4fd8-ba0d-6ae1c27b5df7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"./test_images\", exist_ok=True)\n",
    "\n",
    "!wget -O 'test_images/example_1.png' https://github.com/anjisun221/css_codes/blob/main/ay21t1/Lab04_image_analysis/test_images/example_1.png?raw=true\n",
    "!wget -O 'test_images/example_2.png' https://github.com/anjisun221/css_codes/blob/main/ay21t1/Lab04_image_analysis/test_images/example_2.png?raw=true\n",
    "!wget -O 'test_images/example_3.png' https://github.com/anjisun221/css_codes/blob/main/ay21t1/Lab04_image_analysis/test_images/example_3.png?raw=true\n",
    "!wget -O 'test_images/example_4.png' https://github.com/anjisun221/css_codes/blob/main/ay21t1/Lab04_image_analysis/test_images/example_4.png?raw=true\n",
    "!wget -O 'test_images/example_5.png' https://github.com/anjisun221/css_codes/blob/main/ay21t1/Lab04_image_analysis/test_images/example_5.png?raw=true\n",
    "!wget -O 'test_images/example_6.png' https://github.com/anjisun221/css_codes/blob/main/ay21t1/Lab04_image_analysis/test_images/example_6.png?raw=true\n",
    "!wget -O 'test_images/example_7.png' https://github.com/anjisun221/css_codes/blob/main/ay21t1/Lab04_image_analysis/test_images/example_7.png?raw=true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dpwyd7IiiuMS",
    "outputId": "2963c9f1-11f5-4f78-dffa-aef89a3dd543"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/anjisun221/css_codes/main/ay21t1/Lab04_image_analysis/smt203_lab04_data.csv \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gx2LDoObjnZa"
   },
   "source": [
    "You should see two news folders `facepp21` and `test_images` and one dataset `smt203_lab04_data.csv`!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcpkdrW-iuMS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qlDnVOliuMS"
   },
   "source": [
    "# Face Detection API\n",
    "\n",
    "Face++'s Face Detection API works with 1) online image  or 2) local image file.  \n",
    "\n",
    "In particular, we will call a function `api.detect()` to use the face detection API. \n",
    "\n",
    "The `api.detect()` requires at least one parameter, either `image_url` for online image or `image_file` for local image file. \n",
    "\n",
    "For online image, you need to provide a url to the image (`image_url=YOUR_URL`). For local image, you need to provide a path to the local file (`image_file=YOUR_FILE_PATH`). \n",
    "\n",
    "Then, the `api.detect()` will return a result in a JSON format with various attributes. If you want to get a particular set of attributes, you can use another parameter `return_attributes.` To get gender, age, and smiling level of the face in the image, you can simply pass `return_attributes=\"gender,age,smiling\".` If this parameter is not provided, it will return all attributes. \n",
    "\n",
    "You can find more details about the API from the following API documentation of face detection API:\n",
    "https://console.faceplusplus.com/documents/5679127\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFJabb2miuMT"
   },
   "source": [
    "## Part 1. Face detection using urls (online image files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6sMYkBIiuMT"
   },
   "outputs": [],
   "source": [
    "### import library for using Face++ API\n",
    "from facepp21.facepp import API,File\n",
    "import facepp21.ImagePro\n",
    "\n",
    "### import library to print JSON format prettier :) \n",
    "from pprint import pformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VS4zo1OZiuMT"
   },
   "outputs": [],
   "source": [
    "### Below fundtion will help to print JSON format in a much readable form\n",
    "def print_json_result(result):\n",
    "    print('\\n'.join(\"  \" + i for i in pformat(result, width=75).split('\\n')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oG32FAAiuMU"
   },
   "outputs": [],
   "source": [
    "### Enter your Face++ api_key and api_secret\n",
    "API_KEY = ''\n",
    "API_SECRET = ''\n",
    "\n",
    "### Create an instance of facepp class with your api_key and api_secret\n",
    "### If you don't provide api_key and api_secret, you will see an error message! \n",
    "api = API(api_key=API_KEY, api_secret=API_SECRET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ppqxl-KiuMU"
   },
   "source": [
    "*Here's an example image.* We will detect the faces and their attributes, such as gender, age, and smiling. \n",
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/anjisun221/css_codes/blob/main/ay21t1/Lab04_image_analysis/img/example_unsplash_2.png?raw=true\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "</div>\n",
    "\n",
    "image source: https://unsplash.com/photos/_7l2FS4FicM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwSDMgeIiuMV"
   },
   "outputs": [],
   "source": [
    "### This is the URL to the image\n",
    "detect_img_url = 'https://github.com/anjisun221/css_codes/blob/main/ay21t1/Lab04_image_analysis/img/example_unsplash_2.png?raw=true'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4SZ_anlziuMV",
    "outputId": "16b60e99-cc8e-43d6-ee72-ebdc771632b4"
   },
   "outputs": [],
   "source": [
    "### Calling api.detect() with two parameters: image_url and return attributes\n",
    "res = api.detect(image_url=detect_img_url, return_attributes=\"gender,age,smiling\")\n",
    "\n",
    "### pring the result in a JSON format\n",
    "print_json_result(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbyuKOrDiuMV"
   },
   "source": [
    "What do you see? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKTIfU-CiuMV"
   },
   "source": [
    "#### You can extract attributes information from JSON result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGrAse6RiuMW",
    "outputId": "b2410a87-b602-4fa0-e72a-ff5744cf1792"
   },
   "outputs": [],
   "source": [
    "### below is the information about the first face \n",
    "\n",
    "age = res['faces'][0]['attributes']['age']['value']\n",
    "gender = res['faces'][0]['attributes']['gender']['value']\n",
    "smile = res['faces'][0]['attributes']['smile']['value']\n",
    "print(f\"First face detected - age: {age}, gender: {gender}, smile: {smile}\")\n",
    "\n",
    "age = res['faces'][1]['attributes']['age']['value']\n",
    "gender = res['faces'][1]['attributes']['gender']['value']\n",
    "smile = res['faces'][1]['attributes']['smile']['value']\n",
    "print(f\"Second face detected - age: {age}, gender: {gender}, smile: {smile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbNqptg5iuMW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwdaCwRiiuMW"
   },
   "source": [
    "### Practice 1. Get other features for the image. \n",
    "\n",
    "Face++'s Face Detect API return many other attributes.\n",
    "\n",
    "1) Can you try to request for the following attributes: 1) emotion expressed, 2) result of beauty analysis, and 3) status of skin? Check their other attributes here: https://console.faceplusplus.com/documents/5679127\n",
    "\n",
    "2) Can you extract emotions from the second face detected from the result? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5QlHzzdiuMW"
   },
   "outputs": [],
   "source": [
    "res = # WRITE YOUR CODE HERE \n",
    "\n",
    "### pring the result in a JSON format\n",
    "print_json_result(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEyXUWNIiuMX"
   },
   "outputs": [],
   "source": [
    "emotion_anger = # WRITE YOUR CODE HERE \n",
    "emotion_disgust = # WRITE YOUR CODE HERE \n",
    "emotion_fear = # WRITE YOUR CODE HERE \n",
    "emotion_happiness = # WRITE YOUR CODE HERE \n",
    "emotion_neutral = # WRITE YOUR CODE HERE \n",
    "emotion_sadness = # WRITE YOUR CODE HERE \n",
    "emotion_surprise = # WRITE YOUR CODE HERE \n",
    "\n",
    "\n",
    "print(emotion_anger, emotion_disgust, emotion_fear, emotion_happiness, emotion_neutral, emotion_sadness, emotion_surprise)\n",
    "\n",
    "### Once you print the above line, you should see the following result\n",
    "### 3.122 3.722 0.062 43.219 0.136 49.678 0.062\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TCiCsDTiuMX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayNXAnufiuMX"
   },
   "source": [
    "## Part 2. Face detection using local image files\n",
    "\n",
    "Similar to the part 1, we can use the Face Detect API using the local image file.\n",
    "For this, you need to use parameter called `image_file` and you need to pass the binary data of the image, which you can do by `File(YOUR_IMAGE_FILE_PATH)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OwCdhbAXiuMY",
    "outputId": "f448424e-1292-4e4f-b9d3-6e1085ddf495"
   },
   "outputs": [],
   "source": [
    "### Calling api.detect() with two parameters: image_file and return attributes\n",
    "input_file = './test_images/example_1.png'\n",
    "res = api.detect(image_file = File(input_file), return_attributes=\"gender,age,smiling,emotion\")\n",
    "\n",
    "### pring the result in a JSON format\n",
    "print_json_result(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JT5tai7CiuMY"
   },
   "source": [
    "#### Create dataframe from the JSON result\n",
    "\n",
    "Here we can convert the JSON result into a dataframe. \n",
    "\n",
    "We will just extract age, gender, and smile. But you can add other attributes like emotion as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFtsiVsviuMY",
    "outputId": "fec4dc89-9792-4173-e805-4665ecf5d3a0"
   },
   "outputs": [],
   "source": [
    "res_list = []\n",
    "\n",
    "### forloop for number of faces detected in a face \n",
    "for i in range(len(res['faces'])):\n",
    "    ### If \n",
    "    if 'attributes' in res['faces'][i]:        \n",
    "        age = res['faces'][i]['attributes']['age']['value']\n",
    "        gender = res['faces'][i]['attributes']['gender']['value']\n",
    "        smile = res['faces'][i]['attributes']['smile']['value']\n",
    "    \n",
    "    print(f\"First face detected - age: {age}, gender: {gender}, smile: {smile}\")\n",
    "    res_list.append([input_file, str(i), age, gender, smile])\n",
    "            \n",
    "# populate dataframe with list of faces\n",
    "df = pd.DataFrame(data=res_list,columns=['img_file', 'nth_face', 'age','gender','smile'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "1BKf_fDgiuMY",
    "outputId": "07227125-1737-40b4-82ba-f24f46bb7068"
   },
   "outputs": [],
   "source": [
    "### Check the dataframe \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJYt8UmqiuMY"
   },
   "outputs": [],
   "source": [
    "### Write our dataframe into the file. \n",
    "df.to_csv(\"./test_facepp_restul.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KA6h2GM6iuMZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2VqPKooiuMZ"
   },
   "source": [
    "### Practice 2. Get all 7 images face detected. \n",
    "\n",
    "There should be 7 images in ./test_images.\n",
    "\n",
    "1. Get the face detection results for all 7 images with attributes of Gender, Age, Smiling, and Emotions,\n",
    "1. extract those four information from the JSON format, \n",
    "1. attend them into a list called `res_list`? Then, \n",
    "1. create a dataframe and store the dataframe into a file named `test_facepp_restul_7.csv`. \n",
    "\n",
    "For 1, 2, and 3. You should use For Loop. \n",
    "\n",
    "Each line should contain the following fields: `image_filename`, `nth_face`, `age`,  `gender`, `smile`, `emo_anger`, `emo_disgust`, `emo_fear`, `emo_happiness`, `emo_neutral`, `emo_sadness`, `emo_surprise.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQyxuhpdiuMZ"
   },
   "outputs": [],
   "source": [
    "res_list = []\n",
    "\n",
    "for i in range(1, 8):\n",
    "    print(i)\n",
    "\n",
    "    ### WRITE YOUR CODE\n",
    "\n",
    "    \n",
    "    \n",
    "# populate dataframe with list of faces\n",
    "df = pd.DataFrame(data=res_list,columns=['img_file', 'nth_face', 'age','gender','smile', 'emo_anger', 'emo_disgust', 'emo_fear', 'emo_happiness', 'emo_neutral', 'emo_sadness', 'emo_surprise'])\n",
    "\n",
    "### Write our dataframe into the file. \n",
    "df.to_csv(\"./test_facepp_restul_7.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8J8wjvekUxK"
   },
   "source": [
    "### Practice 3. Which images are with the highest anger, happiness, and sadness? \n",
    "\n",
    "1. Read the file `./test_facepp_restul_7.csv` and store it to a dataframe named `df_tmp.`\n",
    "2. print the dataframe. You can do it by simple typing `df_tmp`\n",
    "3. Find which image is with the highest anger, happiness, or sadness? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-k7Z1E9lDOp"
   },
   "outputs": [],
   "source": [
    "df_tmp = # WRITE YOUR CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKk032xLlEwk"
   },
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ot95nUwlIGf"
   },
   "source": [
    "Which image is with the highest anger, happiness, or sadness? \n",
    "\n",
    "\n",
    "- Your Answer: \n",
    "\n",
    "Does the Face++ Face Detection API capture well the image's emotion? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yG6nQ-flY9l"
   },
   "source": [
    "[Answer]\n",
    "\n",
    "Which image is with the highest anger, happiness, or sadness? \n",
    "\n",
    "- Anger : example_2.png\n",
    "- Happiness : example_3.png\n",
    "- Sadness: example_6.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5X5EtNHilYkc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sgo4WvGiuMa"
   },
   "source": [
    "## Part 3. Analyzing happy places in Singapore\n",
    "\n",
    "Which landmarks are the happiest in Singapore? \n",
    "\n",
    "We've collected 50 posts from Instagram for each of 10 landmarks and got the images. We note that Phantom Buster didn't return image urls when there are multiple photos in one Instagram post. So our data includes only those Instagram post with one image. Then, we ran the Face Detection APIs to detect faces in the images and extract gender, age, smiling, and emotion of the first face. \n",
    "\n",
    "Apart from face features, our data include the following features:\n",
    "- `postId` - unique identifier of Instagram post\n",
    "- `likeCount` - number of likes of the post\n",
    "- `commentCount` - number of comments of the post\n",
    "- `pubDate` - published date of the post\n",
    "- `query` - query used for Phamtom Buster search. A location in this case. \n",
    "- `description` - the caption (text) of the post \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "owZTylBjiuMa",
    "outputId": "45dba5c2-449c-4c1b-af01-a60c15830e6c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./smt203_lab04_data.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMhYeNtkiuMa",
    "outputId": "8c55d69b-b90c-4f2d-e76f-f661e5e491a0"
   },
   "outputs": [],
   "source": [
    "### which landmarks do we have? \n",
    "df['query'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5COldvviuMa",
    "outputId": "cc241db4-cfe8-4687-dac1-2cbac95b25c9"
   },
   "outputs": [],
   "source": [
    "### how many photos each landmark has? \n",
    "df['query'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82OfwJmLiuMa"
   },
   "source": [
    "#### However, not all photos include faces! \n",
    "\n",
    "Let's remove all posts with images without any face! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ud8RiwfjiuMb",
    "outputId": "aad6f2e6-cc1b-449d-d2bf-a71e1579b28f"
   },
   "outputs": [],
   "source": [
    "### below code remove all rows with \"NaN\" on 'img_file' field\n",
    "df_face = df[df['img_file'].notna()]\n",
    "print(df_face.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgFy579fiuMb"
   },
   "source": [
    "so, out of 231 photos, only 95 photos have faces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9KUsh_RiuMb",
    "outputId": "b95f77b1-b300-4e7a-c9fd-7093f5b78463"
   },
   "outputs": [],
   "source": [
    "### number of \n",
    "df_face['query'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13KT9TjViuMb",
    "outputId": "64a36079-3c78-43d5-94ef-cd5e38f3f448"
   },
   "outputs": [],
   "source": [
    "### Let's compute the percentage of number of photos with faces for each landmark. \n",
    "num_photos = dict(df['query'].value_counts())\n",
    "num_photos_with_face = dict(df_face['query'].value_counts())\n",
    "\n",
    "for each in num_photos.keys():\n",
    "    print(f\"{each}: {num_photos_with_face[each]/num_photos[each]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALSH2ZRaiuMb"
   },
   "source": [
    "Gardens by the Bay and Singapore Zoo had the highest proportion of photos with faces! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LOSv7_OEiuMb",
    "outputId": "bd33f311-28e4-4ecc-b62d-42f2377770a2"
   },
   "outputs": [],
   "source": [
    "### Here's the gender distribution\n",
    "df_face['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQRkqqZoiuMb",
    "outputId": "499a9e66-2776-4a8e-d28e-6ebd565d6eed"
   },
   "outputs": [],
   "source": [
    "### Here's age distribution\n",
    "df_face['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxefeSPxiuMb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cljhckyOiuMb"
   },
   "source": [
    "#### Now, let's see which landmark is the happiest. We will use emotion of faces in images. \n",
    "\n",
    "Note that the dataframe `df_face` is the ones including photos with faces only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RKr2-l6iuMc"
   },
   "outputs": [],
   "source": [
    "### we will use seaborn to visualize our data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "UkFVVki3iuMc",
    "outputId": "d627771a-d790-4088-8e42-3dd850f33e11"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax = sns.boxplot(x=\"query\", y=\"emo_happiness\", data=df_face)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yu83CHsZiuMc"
   },
   "source": [
    "Holland Village seems to be the most happiest place, but be careful that we have only two images with faces for Holland village! \n",
    "\n",
    "**Thus, MacRitchie Reservoir, Jewel Changi Airport, and Singapore Zoo seem to be happy places :D**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDNLR41xiuMc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmhLDOWkiuMc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vD5Y4ODDiuMc"
   },
   "source": [
    "### Practice 4. Which landmark receives the most likes? \n",
    "\n",
    "Can you draw a box plot to see which landmark's photos receive more likes? \n",
    "Please use the dataframe `df_face`\n",
    "\n",
    "You can add `showfliers=False` as a parameter to boxplot, to remove the outliers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xb9nWqMmiuMc"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax = # WRITE YOUR CODE \n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USjNXnqxiuMd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6VQ73yKiuMd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab04_image_analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
