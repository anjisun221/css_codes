{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAvLYtjitCHG"
   },
   "source": [
    "Below button will open this notebook in Google CoLab! \n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/anjisun221/css_codes/blob/main/ay21t1/Lab05_text_classification/Lab05_text_classification%20-%20Students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Db5LVNQh7tSE"
   },
   "source": [
    "# Lab 5 - Text classification\n",
    "\n",
    "In this lab, you will learn:\n",
    "* How to use pre-trained model to classify text\n",
    "* How to fine-tune the model to build a classification model\n",
    "* How to evaluate the performance of a model\n",
    "\n",
    "This lab is written by Jisun AN (jisunan@smu.edu.sg) and Michelle KAN (michellekan@smu.edu.sg).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLgbotgLjlmH"
   },
   "source": [
    "#### **[Important]** Change Runtime Type to GPU\n",
    "\n",
    "For this lab, you need to use \"**GPU**.\" On the Menu, click \"**Runtime**\" --> \"**Change Runtime Type**\" and select Hardware Accelerator as \"**GPU**\"!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZp0B5LQ74Kj"
   },
   "source": [
    "# 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOHuBSch76CO"
   },
   "outputs": [],
   "source": [
    "# Packages for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Packages for train/test dataset split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Uncomment below if you want to see errors in more detail.\n",
    "# import os \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e530Jjg7yjO"
   },
   "source": [
    "# 1. Getting the data\n",
    "\n",
    "In this lab, we will use restaurant review data. \n",
    "\n",
    "This data is manually annotated by humans according to their aspect and sentiment. \n",
    "\n",
    "One review may have two or more aspects and thus two or more sentiment. \n",
    "\n",
    "We note that we excluded those conflicting reviews.\n",
    "\n",
    "\"restaurant_reviews.tsv\" is tab-separated file which fields are: \n",
    "\n",
    "- `sid` is review id\n",
    "- `text` is a review\n",
    "- `aspect` refers to the review area of interest. It consists of any of these five labels: <i>food, service, ambience, price</i> \n",
    "- `sentiment` consists of one of these labels: <i>positive, negative, neutral</i>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1634042262076,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "1GPNTihB7mxz",
    "outputId": "3d85db27-636f-48a9-8b9c-f661bb5761aa"
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"https://raw.githubusercontent.com/anjisun221/css_codes/main/ay21t1/Lab05_text_classification/restaurant_reviews_v2.tsv\", sep=\"\\t\")\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLxsM2BKutEt"
   },
   "source": [
    "#### Q1. How many rows are 'positive'? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rYCVv19uWAV"
   },
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "or2ZI3iUu5s-"
   },
   "source": [
    "You answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Bs2O-7hvE92"
   },
   "source": [
    "#### Q2. How many rows are about 'price'? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83Tdfa3wu4_M"
   },
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0Q4mzmBwLzq"
   },
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zj78zXRw6xh"
   },
   "source": [
    "#### Q3. What's the text of the 10th row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gevNcYEMw6Yj"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKnNsQQ6xGcx"
   },
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60HCNCcXxE8H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQrBQ6aEzaxD"
   },
   "source": [
    "![Huffingface](https://huggingface.co/front/assets/huggingface_logo-noborder.svg)\n",
    "\n",
    "#2. Transformer and Hugging Face\n",
    "\n",
    "A transformer is a deep learning model that adopts the mechanism of attention and it has helped to make big breakthroughs in many Natural Language Processing tasks, such as text classification, question and anwsering, and language translations. \n",
    "\n",
    "You can simply consider it as a model that know a lot of language. The pre-trained model is trained with a large amount of texts (billions of sentences) so that it can be fine-tuned for down-stream tasks such as text classificataion. \n",
    "\n",
    "[Hugging Face](https://huggingface.co/) is an  (NLP)-focused startup with a large open-source community, in particular around the Transformers library. ðŸ¤—/Transformers is a python-based library that exposes an API to use many well-known transformer architectures, such as BERT, RoBERTa, GPT-2 or DistilBERT, that obtain state-of-the-art results on a variety of NLP tasks like text classification, information extraction, question answering, and text generation. Those architectures come pre-trained with several sets of weights. Getting started with Transformers only requires to install the pip package: `transformers`\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxNOc38bjCEO"
   },
   "source": [
    "#### **[Important]** Change Runtime Type to GPU\n",
    "\n",
    "For this lab, you need to use \"**GPU**.\" On the Menu, click \"**Runtime**\" --> \"**Change Runtime Type**\" and select Hardware Accelerator as \"**GPU**\"!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvdV8n0X_ud8"
   },
   "source": [
    "Let's install the Transformers and Datasets libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10048,
     "status": "ok",
     "timestamp": 1634042333013,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "Vp6CrLN9_u6N",
    "outputId": "e270c9b3-ce5c-4a29-d8ac-43c24aefc87f"
   },
   "outputs": [],
   "source": [
    "# this will take some time\n",
    "!pip install datasets transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFw3nK3LASmx"
   },
   "source": [
    "The most basic object in the ðŸ¤— Transformers library is the `pipeline`. It connects a model with its necessary preprocessing and postprocessing steps (e.g., tokenizing), allowing us to directly input any text and get an intelligible answer. \n",
    "\n",
    "Below shows one example of text classification pipeline, `sentiment classification`. \n",
    "\n",
    "The text classification pipeline can currently be loaded from `pipeline()` using the following task identifier: `sentiment-analysis` (for classifying sequences according to positive or negative sentiments).\n",
    "\n",
    "The models that this pipeline can use are models that have been fine-tuned on a sequence classification task. See the up-to-date list of available models on [huggingface.co/models](https://huggingface.co/models).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 12832,
     "status": "ok",
     "timestamp": 1634042427260,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "cfHK3DUnYRYe",
    "outputId": "ab209059-ee72-407e-864f-d8554dfa4d86"
   },
   "outputs": [],
   "source": [
    "## This will enable your coLab to use GPU!!! \n",
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZCGFWkeiKK_"
   },
   "source": [
    "### Text classification with Hugging Face's Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-meGpR_iB0af"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wb4gfP3uhMhL"
   },
   "source": [
    "Do you want to classify your sentent based on its sentiment? \n",
    "\n",
    "It's two lines of code wigh Hugging Face pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179,
     "referenced_widgets": [
      "bf06ce91eabe43caaacce5d9b5af748a",
      "f5eaffec383e4651aa97829d96e3f1eb",
      "0eb3194b57214fe89679af964893623d",
      "3a91e3f9cd054219bed0f1cde2d8e4e6"
     ]
    },
    "executionInfo": {
     "elapsed": 8627,
     "status": "ok",
     "timestamp": 1634042474192,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "KQYBEOsK_y04",
    "outputId": "fc97fbad-fc8b-4508-ff19-98b1ae3d3921"
   },
   "outputs": [],
   "source": [
    "# Load the \"sentiment prediction\" model.\n",
    "classifier = pipeline(\"sentiment-analysis\", device = 0)\n",
    "\n",
    "# input: sentence, output: sentiment lable and score\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6hywf9CCft1"
   },
   "source": [
    "We can even pass several sentences!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1634042504425,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "75OZ9X_Z_2uU",
    "outputId": "e6f95c1d-45fe-44f0-b3de-0e9cdae99c07"
   },
   "outputs": [],
   "source": [
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\", \n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCMxyG8jCxOg"
   },
   "source": [
    "By default, this pipeline selects a particular pretrained model that has been fine-tuned for sentiment analysis in English. The model is downloaded and cached when you create the classifier object. If you rerun the command, the cached model will be used instead and there is no need to download the model again.\n",
    "\n",
    "There are three main steps involved when you pass some text to a pipeline:\n",
    "\n",
    "1. The text is preprocessed into a format the model can understand (e.g., tokenizing--split a sentence into a list of words and vectorization--map each word to a numeric value).\n",
    "2. The preprocessed inputs are passed to the model.\n",
    "3. The predictions of the model are post-processed, so you can make sense of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1634042589528,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "8n9w0RhkDMPd",
    "outputId": "a4d338ae-8875-4a52-d3a5-f842474f225f"
   },
   "outputs": [],
   "source": [
    "# let's check back our data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnwXkurVh5nW"
   },
   "source": [
    "Since we have a ready-made model, we will use our data to evalaute the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxkca7cmDMEn"
   },
   "outputs": [],
   "source": [
    "# We extract text and label to build the model\n",
    "\n",
    "sentences = list(df['text'].values) # text will be the inpur to the model\n",
    "y_sentiment_true = list(df['sentiment'].values) # true labels (sentiment)\n",
    "y_aspect_true = list(df['aspect'].values) # true labels (aspect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1634042856079,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "PTUJxPUMiv6i",
    "outputId": "0d36c97e-68e8-4367-ee3c-e892ba4f2652"
   },
   "outputs": [],
   "source": [
    "# sentences is a list of texts of our review data\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20109,
     "status": "ok",
     "timestamp": 1634042886287,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "EA-NdZ6UF5yw",
    "outputId": "96adb09a-672b-4be3-8a23-87fb00f2c668"
   },
   "outputs": [],
   "source": [
    "sentiment_classifier = pipeline(\"sentiment-analysis\", device = 0)\n",
    "sentiment_result = sentiment_classifier(sentences)\n",
    "sentiment_result[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhW_lpgMi63w"
   },
   "source": [
    "To evaluate the prediction results with true labels, we extract the labels from the results. \n",
    "\n",
    "Since our true labels are 'positive' and 'negative' but the predicted labels are in capital letters ('POSITIVE' and 'NEGATIVE') we will need to make them be lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1634042987203,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "GgpeOah2F5kW",
    "outputId": "9540604e-b703-4948-98d8-3a266f61e910"
   },
   "outputs": [],
   "source": [
    "# extract the predicted labels using list comprehension \n",
    "y_sentiment_pred = [result['label'].lower() for result in sentiment_result]\n",
    "y_sentiment_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzO_2QCXH-UL"
   },
   "source": [
    "We will evalaute the classifcation result by using below four metrics: \n",
    "\n",
    "* Accuracy: the percentage of texts that were categorized with the correct tag.\n",
    "* Precision: the percentage of examples the classifier got right out of the total number of examples that it predicted for a given tag.\n",
    "* Recall: the percentage of examples the classifier predicted for a given tag out of the total number of examples it should have predicted for that given tag.\n",
    "* F1 Score: the harmonic mean of precision and recall.\n",
    "\n",
    "For that, we will use sci-kit's `classification_report` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhB7U4nIH0bC"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1634043033008,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "rN-xTktEHwC0",
    "outputId": "f5e0809d-8daa-4e67-c485-bd0ce119a842"
   },
   "outputs": [],
   "source": [
    "# input: true labels and predicted labels\n",
    "print(classification_report(y_sentiment_true, y_sentiment_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DpfTt-Dlweu"
   },
   "source": [
    "Pretty good, right!?\n",
    "\n",
    "But, note that these reviews are quite clean data, and social media is way more dirty and noisy, so you may see very good result when trying it out with your own data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUZTbFJcIGS_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD4epHgnC5DQ"
   },
   "source": [
    "## Zero-shot classification\n",
    "\n",
    "Weâ€™ll start by tackling a more challenging task where we need to classify texts that havenâ€™t been labelled. This is a common scenario in real-world projects because annotating text is usually time-consuming and requires domain expertise. For this use case, the zero-shot-classification pipeline is very powerful: it allows you to specify which labels to use for the classification, so you donâ€™t have to rely on the labels of the pretrained model. Youâ€™ve already seen how the model can classify a sentence as positive or negative using those two labels â€” but it can also classify the text using any other set of labels you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277,
     "referenced_widgets": [
      "8e66f62305794045926a4df70f9f1000",
      "bfababb0514d43c9a8d1ef4992770d25",
      "562001777338402fbcc6279e9d9c714e",
      "6cfcc2369e7c46a2bde060d9ba9922a1",
      "bb2af581005d497189e58e8c69c4d646",
      "33040386f0fb4da99fc9e4188921dc64",
      "75fb45c5ce55463595477e9f20e32e82",
      "2e8928f015654c288e8b86cb816175f8",
      "0d3d77e6e03745abb555ee7d50cbdb7e",
      "c523d89161e742b884797468c9fb6d9b",
      "587a3eee02cf4b9fb2569a3d554e3565",
      "e4e3a38c03024246a0433dd521c72927",
      "6f5780adea7b468f8069ce3260fb54a5",
      "1ef9c01bf15d44958c0fbdffe09a4e33",
      "c1f80c4eb1c14ddfb9e3958e63b7f23d",
      "ba84112278654c429d0c0b5e2339a1f4"
     ]
    },
    "executionInfo": {
     "elapsed": 77525,
     "status": "ok",
     "timestamp": 1634043814647,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "kefc4Ugw_21R",
    "outputId": "7491314d-50f5-4923-d216-31d69d774603"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", device=0)\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6e-T1l6DDyx"
   },
   "source": [
    "This pipeline is called zero-shot because you donâ€™t need to fine-tune the model on your data to use it. It can directly return probability scores for any list of labels you want!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1634044901334,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "qrDFq5ttImuF",
    "outputId": "aec7aa49-aa56-4308-8596-5c47b230da53"
   },
   "outputs": [],
   "source": [
    "classifier(\n",
    "    \"Trump will win\",\n",
    "    candidate_labels=[\"agree\", \"disagree\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buLg3katmNRd"
   },
   "source": [
    "### Exercise 1. Try the zero-shot classification by yourself. \n",
    "\n",
    "Come up with a possible set of labels and example sentence. Then, try to do zero-shot classification with your own exaple. How does it work? Does it make any sense? \n",
    "\n",
    "Share your labels, sentences, and results [here](https://padlet.com/anjisun221/smt203zeroshot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJl69Hs5POoL"
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO-VGtGlmsQq"
   },
   "source": [
    "## Evaluating zero-shot classification\n",
    "\n",
    "Our restaurant review data also has 'aspect' labels.\n",
    "\n",
    "We will now use zero-shot classification to predict the aspect labels given each review. Then, we will evalaute the model's performance on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48984,
     "status": "ok",
     "timestamp": 1634044203463,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "NiF0mXjsDC_G",
    "outputId": "cdb96ca3-90bd-47dd-c8ad-c162081d071f"
   },
   "outputs": [],
   "source": [
    "# Below code will take some time to finish. \n",
    "aspect_classifier = pipeline(\"zero-shot-classification\", device=0)\n",
    "aspect_result = aspect_classifier(list(sentences), candidate_labels=['service', 'food', 'price', 'ambience'],)\n",
    "aspect_result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkFJhEw8qxgP"
   },
   "source": [
    "Since the model returns probabilities for all four labels, we will assign the label with the highest probability to the text. \n",
    "\n",
    "`np.argmax()` will return the index of the list with the higest value.\n",
    "\n",
    "For the first text, the 'food' label has the probability of 0.687, so the index of the highest value is 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1634045045453,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "I4nlRKS1rG-k",
    "outputId": "aa105d97-bc43-49fb-f9fa-8af876ebc077"
   },
   "outputs": [],
   "source": [
    "np.argmax(aspect_result[0]['scores']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1634044932074,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "Tuxa2xFg_281",
    "outputId": "4123d377-8a7b-4998-914a-bf6e427e670e"
   },
   "outputs": [],
   "source": [
    "y_aspect_pred = [result['labels'][np.argmax(result['scores'])] for result in aspect_result]\n",
    "y_aspect_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1634045178377,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "_BLgVUO6_3Fk",
    "outputId": "2152dd4a-2af7-497e-d3c0-b1670d5582d4"
   },
   "outputs": [],
   "source": [
    "# using classification_report to evaluate the predicted labels.\n",
    "print(classification_report(y_aspect_true, y_aspect_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1Mbkps1rwdN"
   },
   "source": [
    "Given that we have four labels, f1-score of 0.67 isn't bad at all! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDGNmbfHr_T4"
   },
   "source": [
    "### Exercise 2. Sentiment analysis by Zero-shot classification \n",
    "\n",
    "1. Use zero-shot classification to classify the restaurant reviews into 'positive' and 'negative' categories. \n",
    "2. Extract the predicted labels from the results\n",
    "3. Evaluate the predicted labels with true labels.\n",
    "4. What's the macro average of f1-score? \n",
    "5. Is it better than using `sentiment-analysis` model in the previous section? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EZ4wFY0svxw"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGQBM1VCsxMu"
   },
   "source": [
    "Your answer to the question 4 of the exercise 2: ??\n",
    "\n",
    "Your answer to the question 5 of the exercise 2: ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvlzAVPmZbMw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyWjg9CG3v4M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCmzPcLQtFLT"
   },
   "source": [
    "# 3. [Optional] Build your own classification model by fine-tuning the pre-trained model \n",
    "\n",
    "So far, the pre-trained models seem to work quite well with our restaurant reveiw data. But what if they don't work with your own data--the evaluation results are too bad to use for your study? \n",
    "\n",
    "In that case, you can build your own classification model by fine-tuning the pre-trained model with your own labeled data. \n",
    "\n",
    "Here, we will learn how you can fine-tune the pre-trained BERT model to build your own classification model! \n",
    "\n",
    "Basically, we will need to go through some steps that was hidden in the `pipeline`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZg4vNl9VoXZ"
   },
   "outputs": [],
   "source": [
    "# We extract text and label to build the model\n",
    "sentences = list(df['text'].values)\n",
    "y_str = list(df['aspect'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfGbUb4Pw65J"
   },
   "source": [
    "Our labels are in string format, but to build the classifier, we need to transform it into numerical form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XiigBxHTyME"
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "for each in y_str:\n",
    "    if each == \"ambience\":\n",
    "        y.append(0)\n",
    "    elif each == \"food\":\n",
    "        y.append(1)\n",
    "    elif each == \"price\":\n",
    "        y.append(2)        \n",
    "    elif each == \"service\":\n",
    "        y.append(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1634046655803,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "f4FCMgOLxEEI",
    "outputId": "ecacff0e-a900-46a4-e98c-299b6457afee"
   },
   "outputs": [],
   "source": [
    "# the 'food' label should be encoded as '1'\n",
    "print(y_str[0], y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZecEOUzTzGT"
   },
   "source": [
    "### Train and test datasets\n",
    "\n",
    "To build our own classifier, we will split our labeled data (restaurant review) into train, validation, and test dataset. \n",
    "\n",
    "[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) is a function in Sklearn model selection for splitting data arrays into two subsets: for training data and for testing data. With this function, you don't need to divide the dataset manually. It has the following syntax:\n",
    "\n",
    "    train_test_split(X, y, train_size=0.*,test_size=0.*, random_state=*)\n",
    "\n",
    "The function takes the following parameters:\n",
    "- `X, y`: the dataset you're selecting to use. Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes.\n",
    "- `train_size`: This parameter sets the size of the training dataset. There are three options: None, which is the default, Int, which requires the exact number of samples, and float, which ranges from 0.1 to 1.0.\n",
    "- `test_size`: This parameter specifies the size of the testing dataset. The default state suits the training size. It will be set to 0.25 if the training size is set to default.\n",
    "- `random_state`: The default mode performs a random split using `np.random`. Alternatively, you can add an integer using an exact number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uqlHVWfTKcm"
   },
   "outputs": [],
   "source": [
    "# Randomly split the data into training (80%) and test (20%) datasets\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.20, random_state=999)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03f57y9jUGuv"
   },
   "source": [
    "We now have a train and test dataset, but let's also also create a validation set which we can use for for evaluation\n",
    "and tuning without tainting our test set results. Sklearn has a convenient utility for creating such splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWvXGqtVThy1"
   },
   "outputs": [],
   "source": [
    "# Randomly split the training data into training (80%) and validation (20%) datasets\n",
    "sentences_train, sentences_val, y_train, y_val = train_test_split(sentences_train, y_train, test_size=.2, random_state=999)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jav8gi4SUWtq"
   },
   "source": [
    "### Tokenization\n",
    "\n",
    "Alright, we've read in our dataset. Now let's tackle tokenization. We'll eventually train a classifier using\n",
    "pre-trained DistilBert, so let's use the DistilBert tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "13701112c443425182f1144923787e65",
      "63b7fdc8825242b48e42201cd5d8e2b9",
      "d5725c1b8a71400499e420a2af2bee8d",
      "af3adb82c500479b9a8e1388a0dbedef",
      "ab19f05a76354308a13d3c3d4f5e8ad0",
      "bda5bc46e8a243c695793c4078595157",
      "c62d7489ab0a45098ce7eee7d34eb1a0",
      "6883132f9a2c423c8d67f07d208b7428",
      "060f8f57973c4ea08c88ce1885937201",
      "e2238b3a38084b1f896ea4c84be62725",
      "2d565957851a41c49686a964b0da9836",
      "de6ecc80a1ce4a04809689610eb5af56",
      "c22fddbfc0c74ac7807da9854b847ca3",
      "f1533e226d2049ebbccda9d25c6e6104"
     ]
    },
    "executionInfo": {
     "elapsed": 1681,
     "status": "ok",
     "timestamp": 1634046995306,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "4PB9V8FHTKRG",
    "outputId": "a0fb5617-27d2-49ec-ed2a-9961f56db9db"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGsS0f0uUaoH"
   },
   "source": [
    "Now we can simply pass our texts to the tokenizer. We'll pass `truncation=True` and `padding=True`, which will\n",
    "ensure that all of our sequences are padded to the same length and are truncated to be no longer model's maximum input\n",
    "length. This will allow us to feed batches of sequences into the model at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iphLN0cHTpZl"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(sentences_train, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(sentences_val, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(sentences_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ld7z8CP7Uiau"
   },
   "source": [
    "Now, let's turn our labels and encodings into a Dataset object. In PyTorch, this is done by subclassing a\n",
    "`torch.utils.data.Dataset` object and implementing `__len__` and `__getitem__`. In TensorFlow, we pass our input\n",
    "encodings and labels to the `from_tensor_slices` constructor method. We put the data in this format so that the data\n",
    "can be easily batched such that each key in the batch encoding corresponds to a named parameter of the\n",
    "`DistilBertForSequenceClassification.forward` method of the model we will train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLh5Zi67UaSg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class myDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = myDataset(train_encodings, y_train)\n",
    "val_dataset = myDataset(val_encodings, y_val)\n",
    "test_dataset = myDataset(test_encodings, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hYfZgG4UzX1"
   },
   "source": [
    "## Train\n",
    "\n",
    "Now that our datasets our ready, we can fine-tune a model either with the ðŸ¤—\n",
    "`Trainer`/`TFTrainer` or with native PyTorch/TensorFlow. See [training](https://huggingface.co/transformers/training.html).\n",
    "\n",
    "The steps above prepared the datasets in the way that the trainer is expected. Now all we need to do is create a model\n",
    "to fine-tune, define the `TrainingArguments`/`TFTrainingArguments` and\n",
    "instantiate a `Trainer`/`TFTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1e82487da1904ec0870247a60cd7ab6a",
      "f667c3482c0b4862bd2a87f0c93c18bc",
      "7f85a40191c2456d8d7783410fa4a9c5",
      "2dc29fed3cda4f0e9c55cd303cbe86bb",
      "11d0c250051c43c1a9f9cbe5124af6de",
      "2c0f3260649840d4a0d5955ac0a23c17",
      "c56b711fde524d7fad5cd3bf9cd67880",
      "1c7e2c06b08644038a80b871e1b00a29",
      "19cb80d3183e4a13a05bc99aadc17c97",
      "593e659afb494a31ba6b5a219d9ab838",
      "fef12ddbccbc4d03bf76069b3633b4e3"
     ]
    },
    "executionInfo": {
     "elapsed": 23762,
     "status": "ok",
     "timestamp": 1634047138866,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "0k1V_iAJU19A",
    "outputId": "84cbbef5-2e79-410f-8c6e-fb4146147675"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# if it's not a binary classification, num_labels should be given! \n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=4)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwG_3DQUZsUY"
   },
   "source": [
    "The training loss is kind of a classification error. \n",
    "\n",
    "You can increase the parameter `num_train_epochs` to train the model longer. This may help to increase the performance of the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-WBEE2Fz9IW"
   },
   "source": [
    "## Test\n",
    "\n",
    "Now, let's evalaute the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xxV5KItR3M0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1634047419384,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "rnhPlUSzO2vq",
    "outputId": "f7b858da-ff8a-4a22-de94-3d266633eee3"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2Z_eRkF0Pvx"
   },
   "source": [
    "The model results in macro average f1-score of 0.78. \n",
    "\n",
    "Our model performs better than zero-shot based model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJhqFMrZ0Ph9"
   },
   "source": [
    "## Save & Load the model\n",
    "\n",
    "Since we see that our model performs well with the test data, we can use it to predict the data that don't have labels! \n",
    "\n",
    "For that, let's try to save and load the new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1634047875179,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "cEbmXK7rO2lO",
    "outputId": "a5e671bf-4b5b-4e46-fe4b-3fdc8132a161"
   },
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1634047877423,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "QWIo7cH0TpHB",
    "outputId": "f1c29e31-6cae-4d2c-aba0-bb4bc23fff7d"
   },
   "outputs": [],
   "source": [
    "new_model = DistilBertForSequenceClassification.from_pretrained(\"./results\", num_labels=4)\n",
    "\n",
    "new_trainer = Trainer(\n",
    "    model=new_model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ytx8arVE2JTE"
   },
   "source": [
    "## Prediction\n",
    "\n",
    "You can predict the labels of your unlabelled data. \n",
    "\n",
    "We will use the sentences in the test data (`sentences_test`) and predict the aspect labels. Here, we will pretend that they don't have any true labels! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1634049280253,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "AmN8QAv47EjH",
    "outputId": "884b38b0-f99b-4f8a-b3f3-e87171374f92"
   },
   "outputs": [],
   "source": [
    "sentences_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1634049336385,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "nKLP5YPC7gt2",
    "outputId": "c443ade2-1f26-45ad-b870-dbc11de71fea"
   },
   "outputs": [],
   "source": [
    "len(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4KmSJ157XFp"
   },
   "outputs": [],
   "source": [
    "# create dataset for prediction\n",
    "new_encodings = tokenizer(sentences_test, truncation=True, padding=True)\n",
    "# create dummy labels with the number of sentences to predict. \n",
    "y_new = np.full(len(sentences_test), 1)\n",
    "new_dataset = myDataset(new_encodings, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634049511055,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "nUqXm2gM67y2",
    "outputId": "80d6282d-a1be-468d-f12f-1ef0a621176b"
   },
   "outputs": [],
   "source": [
    "new_predictions = new_trainer.predict(new_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fWQlSkU3PYK"
   },
   "source": [
    "You can extract the predicted labels with the highest probability using the below code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1634049514898,
     "user": {
      "displayName": "Jisun AN",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09226046566822916181"
     },
     "user_tz": -480
    },
    "id": "ajTVuXrfTonj",
    "outputId": "45bbfe16-f271-48fb-a39a-34ec3a70fef2"
   },
   "outputs": [],
   "source": [
    "new_preds = np.argmax(new_predictions.predictions, axis=-1)\n",
    "new_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Icf5gwOs3UDA"
   },
   "source": [
    "Note that the labels are encoded into numeric form. You may need to convert back to the string format. \n",
    "\n",
    "Remeber that:\n",
    "```\n",
    "y = []\n",
    "for each in y_str:\n",
    "    if each == \"ambience\":\n",
    "        y.append(0)\n",
    "    elif each == \"food\":\n",
    "        y.append(1)\n",
    "    elif each == \"price\":\n",
    "        y.append(2)        \n",
    "    elif each == \"service\":\n",
    "        y.append(3)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiLb5wE84UBh"
   },
   "source": [
    "### [Optional] Exercise 3. Classify the below new texts!\n",
    "\n",
    "You have two new texts. Please use the fine-tuned model to classify those texts into four aspects. \n",
    "\n",
    "Print out the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpBxn5CgfNqS"
   },
   "outputs": [],
   "source": [
    "new_texts = [\"Not too crazy about their sake martini\", \n",
    "             \"But the staff was so horrible to us.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9NxqUY_9b-l"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFIRiZQH8dw1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNMdmgNaES+80vmBE0TxnMZ",
   "collapsed_sections": [],
   "name": "Lab05_text_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "060f8f57973c4ea08c88ce1885937201": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d3d77e6e03745abb555ee7d50cbdb7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11d0c250051c43c1a9f9cbe5124af6de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fef12ddbccbc4d03bf76069b3633b4e3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_593e659afb494a31ba6b5a219d9ab838",
      "value": " 256M/256M [00:05&lt;00:00, 54.2MB/s]"
     }
    },
    "13701112c443425182f1144923787e65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d5725c1b8a71400499e420a2af2bee8d",
       "IPY_MODEL_af3adb82c500479b9a8e1388a0dbedef",
       "IPY_MODEL_ab19f05a76354308a13d3c3d4f5e8ad0"
      ],
      "layout": "IPY_MODEL_63b7fdc8825242b48e42201cd5d8e2b9"
     }
    },
    "19cb80d3183e4a13a05bc99aadc17c97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c7e2c06b08644038a80b871e1b00a29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e82487da1904ec0870247a60cd7ab6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f85a40191c2456d8d7783410fa4a9c5",
       "IPY_MODEL_2dc29fed3cda4f0e9c55cd303cbe86bb",
       "IPY_MODEL_11d0c250051c43c1a9f9cbe5124af6de"
      ],
      "layout": "IPY_MODEL_f667c3482c0b4862bd2a87f0c93c18bc"
     }
    },
    "2c0f3260649840d4a0d5955ac0a23c17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d565957851a41c49686a964b0da9836": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dc29fed3cda4f0e9c55cd303cbe86bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19cb80d3183e4a13a05bc99aadc17c97",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c7e2c06b08644038a80b871e1b00a29",
      "value": 267967963
     }
    },
    "2e8928f015654c288e8b86cb816175f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "33040386f0fb4da99fc9e4188921dc64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "562001777338402fbcc6279e9d9c714e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75fb45c5ce55463595477e9f20e32e82",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_33040386f0fb4da99fc9e4188921dc64",
      "value": "Downloading: 100%"
     }
    },
    "587a3eee02cf4b9fb2569a3d554e3565": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "593e659afb494a31ba6b5a219d9ab838": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63b7fdc8825242b48e42201cd5d8e2b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6883132f9a2c423c8d67f07d208b7428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6cfcc2369e7c46a2bde060d9ba9922a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d3d77e6e03745abb555ee7d50cbdb7e",
      "max": 1154,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e8928f015654c288e8b86cb816175f8",
      "value": 1154
     }
    },
    "75fb45c5ce55463595477e9f20e32e82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f85a40191c2456d8d7783410fa4a9c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c56b711fde524d7fad5cd3bf9cd67880",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2c0f3260649840d4a0d5955ac0a23c17",
      "value": "Downloading: 100%"
     }
    },
    "8e66f62305794045926a4df70f9f1000": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_562001777338402fbcc6279e9d9c714e",
       "IPY_MODEL_6cfcc2369e7c46a2bde060d9ba9922a1",
       "IPY_MODEL_bb2af581005d497189e58e8c69c4d646"
      ],
      "layout": "IPY_MODEL_bfababb0514d43c9a8d1ef4992770d25"
     }
    },
    "ab19f05a76354308a13d3c3d4f5e8ad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d565957851a41c49686a964b0da9836",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e2238b3a38084b1f896ea4c84be62725",
      "value": " 226k/226k [00:00&lt;00:00, 2.53MB/s]"
     }
    },
    "af3adb82c500479b9a8e1388a0dbedef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_060f8f57973c4ea08c88ce1885937201",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6883132f9a2c423c8d67f07d208b7428",
      "value": 231508
     }
    },
    "bb2af581005d497189e58e8c69c4d646": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_587a3eee02cf4b9fb2569a3d554e3565",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c523d89161e742b884797468c9fb6d9b",
      "value": " 1.13k/1.13k [00:00&lt;00:00, 33.1kB/s]"
     }
    },
    "bda5bc46e8a243c695793c4078595157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bfababb0514d43c9a8d1ef4992770d25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c523d89161e742b884797468c9fb6d9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c56b711fde524d7fad5cd3bf9cd67880": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c62d7489ab0a45098ce7eee7d34eb1a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5725c1b8a71400499e420a2af2bee8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c62d7489ab0a45098ce7eee7d34eb1a0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bda5bc46e8a243c695793c4078595157",
      "value": "Downloading: 100%"
     }
    },
    "e2238b3a38084b1f896ea4c84be62725": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f667c3482c0b4862bd2a87f0c93c18bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fef12ddbccbc4d03bf76069b3633b4e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
